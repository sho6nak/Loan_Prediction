{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing for model training(Steps included in Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('Data/sample_data_intw.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['Unnamed: 0','msisdn','pcircle'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['pdate']=pd.to_datetime(dataset['pdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['year'] = dataset['pdate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['month'] = dataset['pdate'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['day'] = dataset['pdate'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['year','pdate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.to_csv('Data/DataPreprocessBasic.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_feature=[feature for feature in dataset.columns if feature not in 'label']\n",
    "scaling_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(dataset[scaling_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform(dataset[scaling_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the train and test set, and add on the Id and SalePrice variables\n",
    "data = pd.concat([dataset[['label']].reset_index(drop=True),\n",
    "                    pd.DataFrame(scaler.transform(dataset[scaling_feature]), columns=scaling_feature)],\n",
    "                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('Data/DataPreprocessedStdNorm.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "## Display all the columns of the dataframe\n",
    "\n",
    "pd.pandas.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('Data/DataPreprocessBasic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_cols = [i for i in dataset.columns if i not in 'label']\n",
    "X = dataset[X_cols]\n",
    "y = dataset['label']\n",
    "#X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>aon</th>\n",
       "      <th>daily_decr30</th>\n",
       "      <th>daily_decr90</th>\n",
       "      <th>rental30</th>\n",
       "      <th>rental90</th>\n",
       "      <th>last_rech_date_ma</th>\n",
       "      <th>last_rech_date_da</th>\n",
       "      <th>last_rech_amt_ma</th>\n",
       "      <th>cnt_ma_rech30</th>\n",
       "      <th>fr_ma_rech30</th>\n",
       "      <th>sumamnt_ma_rech30</th>\n",
       "      <th>medianamnt_ma_rech30</th>\n",
       "      <th>medianmarechprebal30</th>\n",
       "      <th>cnt_ma_rech90</th>\n",
       "      <th>fr_ma_rech90</th>\n",
       "      <th>sumamnt_ma_rech90</th>\n",
       "      <th>medianamnt_ma_rech90</th>\n",
       "      <th>medianmarechprebal90</th>\n",
       "      <th>cnt_da_rech30</th>\n",
       "      <th>fr_da_rech30</th>\n",
       "      <th>cnt_da_rech90</th>\n",
       "      <th>fr_da_rech90</th>\n",
       "      <th>cnt_loans30</th>\n",
       "      <th>amnt_loans30</th>\n",
       "      <th>maxamnt_loans30</th>\n",
       "      <th>medianamnt_loans30</th>\n",
       "      <th>cnt_loans90</th>\n",
       "      <th>amnt_loans90</th>\n",
       "      <th>maxamnt_loans90</th>\n",
       "      <th>medianamnt_loans90</th>\n",
       "      <th>payback30</th>\n",
       "      <th>payback90</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>3055.050000</td>\n",
       "      <td>3065.150000</td>\n",
       "      <td>220.13</td>\n",
       "      <td>260.13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1539</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3078.0</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>3078</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>712.0</td>\n",
       "      <td>12122.000000</td>\n",
       "      <td>12124.750000</td>\n",
       "      <td>3691.26</td>\n",
       "      <td>3691.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5787</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5787.0</td>\n",
       "      <td>5787.0</td>\n",
       "      <td>61.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5787</td>\n",
       "      <td>5787.0</td>\n",
       "      <td>61.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1398.000000</td>\n",
       "      <td>1398.000000</td>\n",
       "      <td>900.13</td>\n",
       "      <td>900.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1539</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>66.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1539</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>66.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>241.0</td>\n",
       "      <td>21.228000</td>\n",
       "      <td>21.228000</td>\n",
       "      <td>159.42</td>\n",
       "      <td>159.42</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>947</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>947</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>947.0</td>\n",
       "      <td>150.619333</td>\n",
       "      <td>150.619333</td>\n",
       "      <td>1098.90</td>\n",
       "      <td>1098.90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2309</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20029.0</td>\n",
       "      <td>2309.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>23496</td>\n",
       "      <td>2888.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    aon  daily_decr30  daily_decr90  rental30  rental90  \\\n",
       "0      0  272.0   3055.050000   3065.150000    220.13    260.13   \n",
       "1      1  712.0  12122.000000  12124.750000   3691.26   3691.26   \n",
       "2      1  535.0   1398.000000   1398.000000    900.13    900.13   \n",
       "3      1  241.0     21.228000     21.228000    159.42    159.42   \n",
       "4      1  947.0    150.619333    150.619333   1098.90   1098.90   \n",
       "\n",
       "   last_rech_date_ma  last_rech_date_da  last_rech_amt_ma  cnt_ma_rech30  \\\n",
       "0                2.0                0.0              1539              2   \n",
       "1               20.0                0.0              5787              1   \n",
       "2                3.0                0.0              1539              1   \n",
       "3               41.0                0.0               947              0   \n",
       "4                4.0                0.0              2309              7   \n",
       "\n",
       "   fr_ma_rech30  sumamnt_ma_rech30  medianamnt_ma_rech30  \\\n",
       "0          21.0             3078.0                1539.0   \n",
       "1           0.0             5787.0                5787.0   \n",
       "2           0.0             1539.0                1539.0   \n",
       "3           0.0                0.0                   0.0   \n",
       "4           2.0            20029.0                2309.0   \n",
       "\n",
       "   medianmarechprebal30  cnt_ma_rech90  fr_ma_rech90  sumamnt_ma_rech90  \\\n",
       "0                  7.50              2            21               3078   \n",
       "1                 61.04              1             0               5787   \n",
       "2                 66.32              1             0               1539   \n",
       "3                  0.00              1             0                947   \n",
       "4                 29.00              8             2              23496   \n",
       "\n",
       "   medianamnt_ma_rech90  medianmarechprebal90  cnt_da_rech30  fr_da_rech30  \\\n",
       "0                1539.0                  7.50            0.0           0.0   \n",
       "1                5787.0                 61.04            0.0           0.0   \n",
       "2                1539.0                 66.32            0.0           0.0   \n",
       "3                 947.0                  2.50            0.0           0.0   \n",
       "4                2888.0                 35.00            0.0           0.0   \n",
       "\n",
       "   cnt_da_rech90  fr_da_rech90  cnt_loans30  amnt_loans30  maxamnt_loans30  \\\n",
       "0              0             0            2            12              6.0   \n",
       "1              0             0            1            12             12.0   \n",
       "2              0             0            1             6              6.0   \n",
       "3              0             0            2            12              6.0   \n",
       "4              0             0            7            42              6.0   \n",
       "\n",
       "   medianamnt_loans30  cnt_loans90  amnt_loans90  maxamnt_loans90  \\\n",
       "0                 0.0          2.0            12                6   \n",
       "1                 0.0          1.0            12               12   \n",
       "2                 0.0          1.0             6                6   \n",
       "3                 0.0          2.0            12                6   \n",
       "4                 0.0          7.0            42                6   \n",
       "\n",
       "   medianamnt_loans90  payback30  payback90  month  day  \n",
       "0                 0.0  29.000000  29.000000      7   20  \n",
       "1                 0.0   0.000000   0.000000      8   10  \n",
       "2                 0.0   0.000000   0.000000      8   19  \n",
       "3                 0.0   0.000000   0.000000      6    6  \n",
       "4                 0.0   2.333333   2.333333      6   22  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model on following algoritims:\n",
    "1) Random Forest\n",
    "<br>2) Ada Boost\n",
    "<br>3) Gradient Boosting Classifier\n",
    "<br>4) SVM 'RBF' kernel\n",
    "<br>5) SVM Linear Kernel\n",
    "<br>5) Logistic Regression\n",
    "<br>6) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Random Forest using Stratified Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157194 52399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.51      0.62      6541\n",
      "           1       0.93      0.98      0.96     45858\n",
      "\n",
      "    accuracy                           0.92     52399\n",
      "   macro avg       0.86      0.75      0.79     52399\n",
      "weighted avg       0.92      0.92      0.91     52399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "print(len(X_train),len(X_test))\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0).fit(X_train,y_train)\n",
    "y_classprop_predicted = clf.predict(X_test)\n",
    "confusion = classification_report(y_test, y_classprop_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) AdaBoost Forest using Stratified Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.41      0.54      6541\n",
      "           1       0.92      0.98      0.95     45858\n",
      "\n",
      "    accuracy                           0.91     52399\n",
      "   macro avg       0.85      0.70      0.75     52399\n",
      "weighted avg       0.90      0.91      0.90     52399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "clf = AdaBoostClassifier(random_state=0).fit(X_train,y_train)\n",
    "y_classprop_predicted = clf.predict(X_test)\n",
    "confusion = classification_report(y_test, y_classprop_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Gradient Bossting Classifier using Stratified Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.47      0.59      6541\n",
      "           1       0.93      0.98      0.95     45858\n",
      "\n",
      "    accuracy                           0.92     52399\n",
      "   macro avg       0.86      0.73      0.77     52399\n",
      "weighted avg       0.91      0.92      0.91     52399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "clf = GradientBoostingClassifier().fit(X_train,y_train)\n",
    "y_classprop_predicted = clf.predict(X_test)\n",
    "confusion = classification_report(y_test, y_classprop_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) SVM RBF Kernel using Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('Data/DataPreprocessedStdNorm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_cols = [i for i in dataset.columns if i not in 'label']\n",
    "X = dataset[X_cols]\n",
    "y = dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.26      0.37      6541\n",
      "           1       0.90      0.98      0.94     45858\n",
      "\n",
      "    accuracy                           0.89     52399\n",
      "   macro avg       0.77      0.62      0.66     52399\n",
      "weighted avg       0.87      0.89      0.87     52399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "clf = SVC(kernel='rbf').fit(X_train,y_train)\n",
    "y_classprop_predicted = clf.predict(X_test)\n",
    "confusion = classification_report(y_test, y_classprop_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) SVM Linear Kernel using Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.01      0.01      6541\n",
      "           1       0.88      1.00      0.93     45858\n",
      "\n",
      "    accuracy                           0.88     52399\n",
      "   macro avg       0.68      0.50      0.47     52399\n",
      "weighted avg       0.83      0.88      0.82     52399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "clf = LinearSVC().fit(X_train,y_train)\n",
    "y_classprop_predicted = clf.predict(X_test)\n",
    "confusion = classification_report(y_test, y_classprop_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Logistic Regression using Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.02      0.03      6541\n",
      "           1       0.88      1.00      0.93     45858\n",
      "\n",
      "    accuracy                           0.88     52399\n",
      "   macro avg       0.76      0.51      0.48     52399\n",
      "weighted avg       0.85      0.88      0.82     52399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "clf = LogisticRegression().fit(X_train,y_train)\n",
    "y_classprop_predicted = clf.predict(X_test)\n",
    "confusion = classification_report(y_test, y_classprop_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64      6541\n",
      "           1       0.94      0.97      0.96     45858\n",
      "\n",
      "    accuracy                           0.92     52399\n",
      "   macro avg       0.84      0.77      0.80     52399\n",
      "weighted avg       0.92      0.92      0.92     52399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "model = XGBClassifier(scale_pos_weight=1).fit(X_train, y_train)\n",
    "y_classprop_predicted = model.predict(X_test)\n",
    "confusion = classification_report(y_test, y_classprop_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classprop_predicted = model.predict(X_test)\n",
    "confusion = classification_report(y_test, y_classprop_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuining for RandomForest\n",
    "<br> Since Random Forest has the highest accuracy, we are going to perform hyperparameter tuining on RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('Data/DataPreprocessBasic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_cols = [i for i in dataset.columns if i not in 'label']\n",
    "X = dataset[X_cols]\n",
    "y = dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 55.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "# max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "rf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, verbose=2, random_state=42, n_jobs = -1,scoring='f1_macro')\n",
    "rf_random.fit(X_train, y_train)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=25, max_features='sqrt', n_estimators=1000,\n",
      "                       random_state=0)\n",
      "0.7888925360755182\n",
      "RandomizedSearchCV(estimator=RandomForestClassifier(random_state=0), n_jobs=-1,\n",
      "                   param_distributions={'max_depth': [5, 10, 15, 20, 25, 30],\n",
      "                                        'max_features': ['auto', 'sqrt'],\n",
      "                                        'min_samples_leaf': [1, 2, 5, 10],\n",
      "                                        'min_samples_split': [2, 5, 10, 15,\n",
      "                                                              100],\n",
      "                                        'n_estimators': [100, 200, 300, 400,\n",
      "                                                         500, 600, 700, 800,\n",
      "                                                         900, 1000, 1100,\n",
      "                                                         1200]},\n",
      "                   random_state=42, scoring='f1_macro', verbose=2)\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_estimator_)\n",
    "print(rf_random.best_score_)\n",
    "print(rf_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7888925360755182\n",
      "[[ 3318  3223]\n",
      " [  861 44997]]\n",
      "0.9220595812897193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.51      0.62      6541\n",
      "           1       0.93      0.98      0.96     45858\n",
      "\n",
      "    accuracy                           0.92     52399\n",
      "   macro avg       0.86      0.74      0.79     52399\n",
      "weighted avg       0.92      0.92      0.91     52399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_score_)\n",
    "best_est = rf_random.best_estimator_\n",
    "y_pred=best_est.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Class Weight in Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight=dict({0:10,1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 10, 1: 1}, max_depth=25,\n",
       "                       max_features='sqrt', n_estimators=1000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(n_estimators=1000, min_samples_split= 2, min_samples_leaf= 1, max_features= 'sqrt', max_depth= 25, class_weight=class_weight)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 19610     11]\n",
      " [  3212 134361]]\n",
      "0.9794966729010013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92     19621\n",
      "           1       1.00      0.98      0.99    137573\n",
      "\n",
      "    accuracy                           0.98    157194\n",
      "   macro avg       0.93      0.99      0.96    157194\n",
      "weighted avg       0.98      0.98      0.98    157194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_train)\n",
    "print(confusion_matrix(y_train,y_pred))\n",
    "print(accuracy_score(y_train,y_pred))\n",
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3923  2618]\n",
      " [ 1740 44118]]\n",
      "0.9168304738640051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64      6541\n",
      "           1       0.94      0.96      0.95     45858\n",
      "\n",
      "    accuracy                           0.92     52399\n",
      "   macro avg       0.82      0.78      0.80     52399\n",
      "weighted avg       0.91      0.92      0.91     52399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Imb Learn\n",
    "<br>We are going to use open source library imb learn and perform various techniques to deal with imbalance data\n",
    "<br>Some of techniques we are going to use are:\n",
    "<br>1) UnderSampling\n",
    "<br>2) OverSampling\n",
    "<br>3) SMOTETomek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('Data/DataPreprocessBasic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_cols = [i for i in dataset.columns if i not in 'label']\n",
    "X = dataset[X_cols]\n",
    "y = dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 137573, 0: 19621})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import NearMiss\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:635: FutureWarning: Pass sampling_strategy=0.8 as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.9 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({1: 137573, 0: 19621})\n",
      "The number of classes after fit Counter({1: 24526, 0: 19621})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "ns=NearMiss(0.8)\n",
    "X_train_ns,y_train_ns=ns.fit_sample(X_train,y_train)\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train_ns,y_train_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5576   965]\n",
      " [33547 12311]]\n",
      "0.34136147636405273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.85      0.24      6541\n",
      "           1       0.93      0.27      0.42     45858\n",
      "\n",
      "    accuracy                           0.34     52399\n",
      "   macro avg       0.53      0.56      0.33     52399\n",
      "weighted avg       0.83      0.34      0.39     52399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os=SMOTETomek(0.75)\n",
    "X_train_ns,y_train_ns=os.fit_sample(X_train,y_train)\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train_ns,y_train_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('Data/DataPreprocessBasic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_cols = [i for i in dataset.columns if i not in 'label']\n",
    "X = dataset[X_cols]\n",
    "y = dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_testCV, y_train, y_testCV = train_test_split(X, y, stratify=y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({1: 183431, 0: 26162})\n",
      "The number of classes after fit Counter({1: 183431, 0: 137573})\n"
     ]
    }
   ],
   "source": [
    "os=RandomOverSampler(0.75)\n",
    "X_train_ns,y_train_ns=os.fit_sample(X,y)\n",
    "print(\"The number of classes before fit {}\".format(Counter(y)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [     0      1      3 ... 321000 321001 321003] TEST: [     2      4      6 ... 320996 320997 321002]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95     34394\n",
      "           1       0.98      0.94      0.96     45857\n",
      "\n",
      "    accuracy                           0.96     80251\n",
      "   macro avg       0.95      0.96      0.96     80251\n",
      "weighted avg       0.96      0.96      0.96     80251\n",
      "\n",
      "TRAIN: [     1      2      3 ... 321000 321002 321003] TEST: [     0     10     22 ... 320984 320994 321001]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95     34393\n",
      "           1       0.99      0.94      0.96     45858\n",
      "\n",
      "    accuracy                           0.96     80251\n",
      "   macro avg       0.95      0.96      0.96     80251\n",
      "weighted avg       0.96      0.96      0.96     80251\n",
      "\n",
      "TRAIN: [     0      1      2 ... 321001 321002 321003] TEST: [     3      5      7 ... 320991 320992 320999]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95     34393\n",
      "           1       0.98      0.94      0.96     45858\n",
      "\n",
      "    accuracy                           0.96     80251\n",
      "   macro avg       0.95      0.96      0.96     80251\n",
      "weighted avg       0.96      0.96      0.96     80251\n",
      "\n",
      "TRAIN: [     0      2      3 ... 320999 321001 321002] TEST: [     1      9     13 ... 320998 321000 321003]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95     34393\n",
      "           1       0.99      0.94      0.96     45858\n",
      "\n",
      "    accuracy                           0.96     80251\n",
      "   macro avg       0.95      0.96      0.96     80251\n",
      "weighted avg       0.96      0.96      0.96     80251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=1)\n",
    "for train_index, test_index in skf.split(X_train_ns, y_train_ns):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X_train_ns.iloc[list(train_index)], X_train_ns.iloc[list(test_index)]\n",
    "    y_train, y_test = y_train_ns.iloc[list(train_index)], y_train_ns.iloc[list(test_index)]\n",
    "    classifier=RandomForestClassifier(max_depth=20)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred=classifier.predict(X_test)\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:635: FutureWarning: Pass sampling_strategy=0.75 as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.9 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({1: 165067, 0: 23566})\n",
      "The number of classes after fit Counter({1: 165067, 0: 123800})\n"
     ]
    }
   ],
   "source": [
    "os=RandomOverSampler(0.75)\n",
    "X_train_ns,y_train_ns=os.fit_sample(X_train,y_train)\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(max_depth=20)\n",
    "classifier.fit(X_train_ns,y_train_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88     23566\n",
      "           1       1.00      0.96      0.98    165067\n",
      "\n",
      "    accuracy                           0.97    188633\n",
      "   macro avg       0.90      0.98      0.93    188633\n",
      "weighted avg       0.97      0.97      0.97    188633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_train)\n",
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.69      0.66      2596\n",
      "           1       0.96      0.94      0.95     18364\n",
      "\n",
      "    accuracy                           0.91     20960\n",
      "   macro avg       0.79      0.82      0.81     20960\n",
      "weighted avg       0.92      0.91      0.91     20960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.60436328e-02, 9.83956367e-01],\n",
       "       [1.60009120e-02, 9.83999088e-01],\n",
       "       [2.63372292e-01, 7.36627708e-01],\n",
       "       ...,\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.62601626e-04, 9.99837398e-01],\n",
       "       [5.52241436e-02, 9.44775856e-01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.32670845, 1.        ]),\n",
       " array([0.        , 0.94897292, 1.        ]),\n",
       " array([2, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(classifier, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('model.pkl','rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
